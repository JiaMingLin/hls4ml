{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a brevitas binary neural network for MNIST\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant import Int8WeightPerTensorFloat, SignedBinaryWeightPerTensorConst\n",
    "from brevitas.quant import Int8ActPerTensorFloat, SignedBinaryActPerTensorConst\n",
    "\n",
    "class SignedBinaryWeightPerTensorConstOne(SignedBinaryWeightPerTensorConst):\n",
    "    scaling_const = 1\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryNet, self).__init__()\n",
    "        \n",
    "        # 輸入層到第一個隱藏層\n",
    "        self.fc1 = qnn.QuantLinear(\n",
    "            5,  # MNIST 輸入維度 (28x28)\n",
    "            5,\n",
    "            bias=True,\n",
    "            input_quant=SignedBinaryActPerTensorConst,\n",
    "            weight_quant=SignedBinaryWeightPerTensorConstOne\n",
    "        )\n",
    "        \n",
    "        # 第一個隱藏層到第二個隱藏層\n",
    "        self.fc2 = qnn.QuantLinear(\n",
    "            5,\n",
    "            5,\n",
    "            bias=True, \n",
    "            input_quant=SignedBinaryActPerTensorConst,\n",
    "            weight_quant=SignedBinaryWeightPerTensorConstOne\n",
    "        )\n",
    "\n",
    "        self.quant_relu = qnn.QuantReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 前向傳播\n",
    "        x = self.quant_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model ...\n",
      "dict_keys(['Conv1d', 'QuantConv1d', 'Conv2d', 'QuantConv2d', 'cat', 'concat', 'concatenate', 'add', 'mul', 'multiply', 'sub', 'subtract', 'fmin', 'minimum', 'fmax', 'maximum', 'View', 'squeeze', 'unsqueeze', 'Flatten', 'Upsample', 'UpsamplingNearest2d', 'UpsamplingBilinear2d', 'Linear', 'QuantLinear', 'Softmax', 'ReLU', 'LeakyReLU', 'Threshold', 'ELU', 'PReLU', 'Sigmoid', 'Tanh', 'QuantReLU', 'QuantSigmoid', 'QuantTanh', 'BatchNorm2d', 'BatchNorm1d', 'Batch_norm', 'MaxPool1d', 'MaxPool2d', 'AvgPool1d', 'AvgPool2d', 'QuantMaxPool1d', 'QuantMaxPool2d'])\n",
      "Topology:\n",
      "Layer name: fc1, layer type: Dense, input shape: [[None, 10]]\n",
      "Layer name: quant_relu, layer type: Activation, input shape: [[None, 10]]\n",
      "Layer name: fc2, layer type: Dense, input shape: [[None, 10]]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from hls4ml.converters import convert_from_pytorch_model\n",
    "from hls4ml.utils.config import config_from_pytorch_model\n",
    "# 初始化 BinaryNet 模型\n",
    "model = BinaryNet()\n",
    "\n",
    "# 設定輸入形狀\n",
    "input_shape = (None, 5)  # MNIST 數據集的形狀\n",
    "\n",
    "# 從模型生成配置\n",
    "config = config_from_pytorch_model(model, backend='Vitis')\n",
    "\n",
    "# 設定輸出目錄\n",
    "output_dir = 'hls4ml_bnn_prj'\n",
    "\n",
    "# 轉換為 HLS 模型\n",
    "hls_model_init = convert_from_pytorch_model(\n",
    "    model,\n",
    "    input_shape,\n",
    "    hls_config=config,\n",
    "    output_dir=output_dir,\n",
    "    backend='Vitis',\n",
    "    io_type='io_parallel'\n",
    ")\n",
    "\n",
    "# 編譯 HLS 模型\n",
    "hls_model_init.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch模型預測結果:\n",
      "[[ 3.9261074  2.183936  -1.9792562  1.927779   2.1620696 -4.2387676\n",
      "  -3.965987   3.8596807  2.0498013  1.8720356]]\n",
      "\n",
      "HLS模型預測結果:\n",
      "[[-5.6972656 -5.439453  -5.602539  -5.6953125 -5.461914  -5.8623047\n",
      "  -5.5898438 -5.763672  -5.5742188 -5.751953 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/miniconda3/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:1413: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1925.)\n",
      "  return super().rename(names)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.01, atol=0.01\n\nMismatched elements: 10 / 10 (100%)\nMax absolute difference: 9.623373\nMax relative difference: 4.072566\n x: array([[-5.697266, -5.439453, -5.602539, -5.695312, -5.461914, -5.862305,\n        -5.589844, -5.763672, -5.574219, -5.751953]], dtype=float32)\n y: array([[ 3.926107,  2.183936, -1.979256,  1.927779,  2.16207 , -4.238768,\n        -3.965987,  3.859681,  2.049801,  1.872036]], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(hls_prediction)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 計算預測結果的相對誤差\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhls_prediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpytorch_prediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m兩個模型的預測結果在允許的誤差範圍內相符\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/numpy/testing/_private/utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    858\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    860\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    861\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.01, atol=0.01\n\nMismatched elements: 10 / 10 (100%)\nMax absolute difference: 9.623373\nMax relative difference: 4.072566\n x: array([[-5.697266, -5.439453, -5.602539, -5.695312, -5.461914, -5.862305,\n        -5.589844, -5.763672, -5.574219, -5.751953]], dtype=float32)\n y: array([[ 3.926107,  2.183936, -1.979256,  1.927779,  2.16207 , -4.238768,\n        -3.965987,  3.859681,  2.049801,  1.872036]], dtype=float32)"
     ]
    }
   ],
   "source": [
    "# 生成隨機輸入數據\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 生成一個隨機輸入張量\n",
    "x = torch.randn(1, 10)  # 批次大小為1,784個特徵\n",
    "# 使用PyTorch模型進行預測\n",
    "pytorch_prediction = model(x).detach().numpy()\n",
    "\n",
    "# 使用HLS模型進行預測\n",
    "hls_prediction = hls_model_init.predict(x.numpy())\n",
    "\n",
    "# 重塑HLS預測結果以匹配PyTorch預測的形狀\n",
    "hls_prediction = np.reshape(hls_prediction, pytorch_prediction.shape)\n",
    "\n",
    "# 比較兩個模型的預測結果\n",
    "print(\"PyTorch模型預測結果:\")\n",
    "print(pytorch_prediction)\n",
    "print(\"\\nHLS模型預測結果:\")\n",
    "print(hls_prediction)\n",
    "\n",
    "# 計算預測結果的相對誤差\n",
    "np.testing.assert_allclose(hls_prediction, pytorch_prediction, rtol=1e-2, atol=0.01)\n",
    "print(\"\\n兩個模型的預測結果在允許的誤差範圍內相符\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一層量化後的權重:\n",
      "QuantTensor(value=tensor([[-1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.],\n",
      "        [ 1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.],\n",
      "        [ 1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.],\n",
      "        [ 1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [-1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1.],\n",
      "        [-1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.],\n",
      "        [-1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.],\n",
      "        [ 1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.]],\n",
      "       grad_fn=<MulBackward0>), scale=tensor(1.), zero_point=tensor(0.), bit_width=tensor(1.), signed_t=tensor(True), training_t=tensor(True))\n",
      "HLS模型第一層量化後的權重:\n",
      "[[-1  1 -1  1  1  1 -1 -1 -1  1]\n",
      " [-1 -1 -1 -1 -1  1 -1  1  1  1]\n",
      " [-1  1 -1 -1 -1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1  1  1 -1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1 -1 -1  1  1 -1]\n",
      " [ 1 -1 -1  1 -1  1 -1 -1 -1  1]\n",
      " [ 1 -1  1  1  1  1 -1  1  1 -1]\n",
      " [ 1 -1  1 -1  1  1 -1  1 -1 -1]\n",
      " [ 1 -1 -1 -1 -1  1 -1 -1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1  1  1 -1  1]]\n"
     ]
    }
   ],
   "source": [
    "# 打印PyTorch模型第一層量化後的權重\n",
    "quant_weight = model.fc1.quant_weight()\n",
    "print(\"第一層量化後的權重:\")\n",
    "print(quant_weight)\n",
    "\n",
    "import numpy as np\n",
    "hls_weight = np.array([-1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1])\n",
    "print(\"HLS模型第一層量化後的權重:\")\n",
    "print(hls_weight.reshape(10, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
